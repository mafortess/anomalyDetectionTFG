# my global config
global:
  scrape_interval: 15s # Set the scrape interval to every 15 seconds. Default is every 1 minute.
  evaluation_interval: 15s # Evaluate rules every 15 seconds. The default is every 1 minute.
  # scrape_timeout is set to the global default (10s).

# Alertmanager configuration
alerting:
  alertmanagers:
    - static_configs:
        - targets:
           - "localhost:9093"

# Load rules once and periodically evaluate them according to the global 'evaluation_interval'.
rule_files:
    - "rules/*.yml"

#remote_write:
 # - url: "http:localhost:8125/metrics"
#remote_write:
 # - url: "http://localhost:8086/api/v2/write?org=TFG_project&bucket=TFG_data&precision=s"
  #  authorization:
   #   credentials: "PrO58TuPkcGraEdDtUzl4wPcRFPWu9VURn_x_aPvOq_wfqoN9SX6-gDAhky-4OwdALkQTufGoT-45HeJt9M9zA=="


remote_read:
  - url: "http://localhost:8086/api/v2/read?org=TFG_project"
    authorization:
      credentials: "PrO58TuPkcGraEdDtUzl4wPcRFPWu9VURn_x_aPvOq_wfqoN9SX6-gDAhky-4OwdALkQTufGoT-45HeJt9M9zA=="

scrape_config_files:
  - "scrape_configs/*.yml"

# A scrape configuration containing exactly one endpoint to scrape:
# Here it's Prometheus itself.
scrape_configs:
  # The job name is added as a label `job=<job_name>` to any timeseries scraped from this config.
  - job_name: "prometheus"    # metrics_path defaults to '/metrics' # scheme defaults to 'http'.
    static_configs:
      - targets: ["localhost:9090"]
  - job_name: "esp32"
    static_configs:
      - targets: ["192.168.1.100:80"]
  - job_name: "debiancluster"
    static_configs:
       - targets: ["192.168.1.136:9090"]
  - job_name: 'cadvisor'
    scrape_interval: 5s
    static_configs:
      - targets: ['localhost:8081']
  - job_name: 'kubernetes-prometheus-federation'
    scrape_interval: 30s  # Intervalo recomendado, ajusta seg√∫n necesidades
    static_configs:
      - targets:
        - '192.168.49.2:31236'  # Usa la IP y el NodePort o LoadBalancer del Prometheus en Kubernetes
